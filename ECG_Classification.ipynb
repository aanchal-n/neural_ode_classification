{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mit_train = pd.read_csv('./data/mitbih_train.csv', header=None)\n",
    "mit_test = pd.read_csv('./data/mitbih_test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target from data\n",
    "y_train = mit_train[187]\n",
    "X_train = mit_train.loc[:, :186]\n",
    "\n",
    "y_test = mit_test[187]\n",
    "X_test = mit_test.loc[:, :186]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = map(\n",
    "    torch.from_numpy, \n",
    "    (X_train.values, y_train.values, X_test.values, y_test.values)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 3D tensor\n",
    "X_train = X_train.unsqueeze(1)\n",
    "X_test = X_test.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "bs = 128\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from models import norm, ResBlock, ODEfunc, ODENet, Flatten, count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers adapted from https://pytorch.org/tutorials/beginner/nn_tutorial.html\n",
    "\n",
    "def get_model(is_odenet=True, dim=64, adam=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Initialize ResNet or ODENet with optimizer.\n",
    "    \"\"\"\n",
    "    downsampling_layers = [\n",
    "        nn.Conv1d(1, dim, 3, 1),\n",
    "        norm(dim),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv1d(dim, dim, 4, 2, 1),\n",
    "        norm(dim),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv1d(dim, dim, 4, 2, 1)\n",
    "    ]\n",
    "\n",
    "    feature_layers = [ODENet(ODEfunc(dim), **kwargs)] if is_odenet else [ResBlock(dim) for _ in range(6)]\n",
    "\n",
    "    fc_layers = [norm(dim), nn.ReLU(inplace=True), nn.AdaptiveAvgPool1d(1), Flatten(), nn.Linear(dim, 5)]\n",
    "\n",
    "    model = nn.Sequential(*downsampling_layers, *feature_layers, *fc_layers)\n",
    "\n",
    "    opt = optim.Adam(model.parameters()) if adam else optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "    return model, opt\n",
    "\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    \"\"\"\n",
    "    Calculate loss and update weights if training.\n",
    "    \"\"\"\n",
    "    loss = loss_func(model(xb.float()), yb.long())\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    \"\"\"\n",
    "    Train neural network model.\n",
    "    \"\"\"\n",
    "    num_batches = len(train_dl)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Training... epoch {epoch + 1}\")\n",
    "        \n",
    "        model.train()   # Set model to training mode\n",
    "        batch_count = 0\n",
    "        start = time.time()\n",
    "        for xb, yb in train_dl:\n",
    "            batch_count += 1\n",
    "            curr_time = time.time()\n",
    "            percent = round(batch_count/len(train_dl) * 100, 1)\n",
    "            elapsed = round((curr_time - start)/60, 1)\n",
    "            print(f\"    Percent trained: {percent}%  Time elapsed: {elapsed} min\", end='\\r')\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "            \n",
    "            \n",
    "\n",
    "        model.eval()    # Set model to validation mode\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(f\"\\n    val loss: {round(val_loss, 2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "odenet, odeopt = get_model(adam=False, rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet, resopt = get_model(is_odenet=False, adam=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... epoch 1\n",
      "    Percent trained: 100.0%  Time elapsed: 11.0 min\n",
      "    val loss: 0.36\n",
      "\n",
      "Training... epoch 2\n",
      "    Percent trained: 100.0%  Time elapsed: 10.8 min\n",
      "    val loss: 0.79\n",
      "\n",
      "Training... epoch 3\n",
      "    Percent trained: 100.0%  Time elapsed: 10.4 min\n",
      "    val loss: 0.23\n",
      "\n",
      "Training... epoch 4\n",
      "    Percent trained: 100.0%  Time elapsed: 10.1 min\n",
      "    val loss: 0.13\n",
      "\n",
      "Training... epoch 5\n",
      "    Percent trained: 100.0%  Time elapsed: 10.1 min\n",
      "    val loss: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(5, resnet, F.cross_entropy, resopt, train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... epoch 1\n",
      "    Percent trained: 100.0%  Time elapsed: 61.9 min\n",
      "    val loss: 0.23\n",
      "\n",
      "Training... epoch 2\n",
      "    Percent trained: 100.0%  Time elapsed: 71.2 min\n",
      "    val loss: 0.14\n",
      "\n",
      "Training... epoch 3\n",
      "    Percent trained: 100.0%  Time elapsed: 73.6 min\n",
      "    val loss: 0.12\n",
      "\n",
      "Training... epoch 4\n",
      "    Percent trained: 100.0%  Time elapsed: 80.5 min\n",
      "    val loss: 0.09\n",
      "\n",
      "Training... epoch 5\n",
      "    Percent trained: 100.0%  Time elapsed: 97.4 min\n",
      "    val loss: 0.09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(5, odenet, F.cross_entropy, odeopt, train_dl, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_test.float())\n",
    "    preds = torch.argmax(F.softmax(logits, dim=1), axis=1).numpy()\n",
    "    return (preds == y_test.numpy()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet accuracy: 0.974\n",
      "ODENet accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "print(f\"ResNet accuracy: {round(accuracy(resnet, X_test, y_test), 3)}\")\n",
    "print(f\"ODENet accuracy: {round(accuracy(odenet, X_test, y_test), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.83\n",
       "1.0    0.03\n",
       "2.0    0.07\n",
       "3.0    0.01\n",
       "4.0    0.07\n",
       "Name: 187, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "round(mit_test[187].value_counts(normalize=True).sort_index(), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models perform well on the test set with accuracies above 97%. This is significantly above the baseline accuracy of 83%. Therefore, the models both generalize well. The ResNet trained for only an hour while the ODENet trained for over seven hours. However, a benefit of the ODENet can be seen below. It has almost exactly 1/3 of the parameters as the ResNet and yet performed slightly better. This leads to the fact that Neural ODEs use constant memory (although with a high memory overhead due to the adjoint method). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tunable parameters in...\n",
      "    ResNet: 182853\n",
      "    ODENet: 59333\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tunable parameters in...\")\n",
    "print(f\"    ResNet: {count_parameters(resnet)}\")\n",
    "print(f\"    ODENet: {count_parameters(odenet)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
